{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0763c64",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "INICIANDO PREPROCESAMIENTO DE DATOS Y SELECCIÓN DE CARACTERÍSTICAS...\n",
      "--------------------------------------------------\n",
      "Datos cargados exitosamente desde: C:\\Users\\Víctor\\Documents\\PaintFormulatorAI\\notebooks\\..\\data\\raw\\simulated_paint_data.csv\n",
      "Número de filas inicial: 5000, Número de columnas inicial: 16\n"
     ]
    }
   ],
   "source": [
    "# 02_Preprocesamiento_y_Seleccion_Caracteristicas.ipynb\n",
    "\n",
    "# ==============================================================================\n",
    "# PREPROCESAMIENTO DE DATOS Y SELECCIÓN DE CARACTERÍSTICAS\n",
    "# ==============================================================================\n",
    "\n",
    "# Este notebook se enfoca en preparar los datos para el modelado de Machine Learning.\n",
    "# Incluye la codificación de variables categóricas, el escalado de variables numéricas,\n",
    "# y la división del dataset en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. Configuración Inicial y Carga de Datos\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import joblib # Para guardar el preprocesador si es necesario\n",
    "\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"INICIANDO PREPROCESAMIENTO DE DATOS Y SELECCIÓN DE CARACTERÍSTICAS...\")\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "# Definir la ruta al archivo de datos CSV generado en el EDA\n",
    "data_path = os.path.join(os.getcwd(), '..', 'data', 'raw', 'simulated_paint_data.csv')\n",
    "\n",
    "# Verificar si el archivo existe antes de cargarlo\n",
    "if not os.path.exists(data_path):\n",
    "    print(f\"ERROR: No se encontró el archivo de datos en: {data_path}\")\n",
    "    print(\"Por favor, asegúrate de haber ejecutado 'python src/data_generator.py' desde la raíz del proyecto.\")\n",
    "else:\n",
    "    # Cargar el dataset\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Datos cargados exitosamente desde: {data_path}\")\n",
    "    print(f\"Número de filas inicial: {df.shape[0]}, Número de columnas inicial: {df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5942919d-a432-40e6-b18b-8738336b3e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "2. IDENTIFICACIÓN DE TIPOS DE COLUMNAS\n",
      "--------------------------------------------------\n",
      "Variable objetivo 'y' (exito) separada. X shape: (5000, 15), y shape: (5000,)\n",
      "\n",
      "Características Numéricas identificadas: ['resina_pct', 'pigmento_pct', 'solvente_pct', 'aditivo_pct', 'temperatura_mezcla_C', 'tiempo_mezcla_min', 'viscosidad_cp', 'brillo_unidades', 'poder_cubriente', 'resistencia_abrasion_ciclos', 'estabilidad_almacenamiento_dias']\n",
      "Características Categóricas identificadas: ['calidad_resina', 'tipo_pigmento', 'tipo_solvente', 'proveedor_aditivo']\n",
      "\n",
      "Explicación para Leonardo (Identificación de Columnas):\n",
      "Hemos separado los datos en 'X' (las características que describen la formulación y proceso)\n",
      "y 'y' (el resultado 'Éxito' o 'Falla' que queremos predecir).\n",
      "Es crucial identificar qué características son numéricas (como porcentajes, temperaturas) y cuáles son categóricas (como tipos o proveedores),\n",
      "ya que cada tipo requiere un tratamiento diferente antes de que los modelos de Machine Learning puedan entenderlas.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 2. Identificación de Tipos de Columnas\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--------------------------------------------------\")\n",
    "print(\"2. IDENTIFICACIÓN DE TIPOS DE COLUMNAS\")\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "# Separar la variable objetivo (target) de las características (features)\n",
    "X = df.drop('exito', axis=1) # Características\n",
    "y = df['exito']             # Variable objetivo\n",
    "\n",
    "print(f\"Variable objetivo 'y' (exito) separada. X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "# Identificar columnas numéricas y categóricas para el preprocesamiento\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "print(f\"\\nCaracterísticas Numéricas identificadas: {numerical_features}\")\n",
    "print(f\"Características Categóricas identificadas: {categorical_features}\")\n",
    "\n",
    "print(\"\\nExplicación para Leonardo (Identificación de Columnas):\")\n",
    "print(\"Hemos separado los datos en 'X' (las características que describen la formulación y proceso)\")\n",
    "print(\"y 'y' (el resultado 'Éxito' o 'Falla' que queremos predecir).\")\n",
    "print(\"Es crucial identificar qué características son numéricas (como porcentajes, temperaturas) y cuáles son categóricas (como tipos o proveedores),\")\n",
    "print(\"ya que cada tipo requiere un tratamiento diferente antes de que los modelos de Machine Learning puedan entenderlas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1f2f11-f484-40a1-833e-53f927abc7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "3. PREPROCESAMIENTO DE DATOS\n",
      "--------------------------------------------------\n",
      "\n",
      "Preprocesador configurado:\n",
      "- Columnas numéricas se escalarán con StandardScaler (media=0, desv_est=1).\n",
      "- Columnas categóricas se codificarán con OneHotEncoder (variables binarias por categoría).\n",
      "\n",
      "Explicación para Leonardo (Preprocesamiento):\n",
      "Esta es una fase técnica donde preparamos los datos para el 'cerebro' del Machine Learning.\n",
      "1. 'Escalado de Numéricas': Componentes como 'resina_pct' o 'temperatura_mezcla_C' tienen rangos muy diferentes.\n",
      "   Al 'escalarlos', nos aseguramos de que ninguno de ellos 'domine' al modelo solo por tener números más grandes.\n",
      "   Esto ayuda a que el modelo aprenda de manera justa de todas las características.\n",
      "2. 'Codificación de Categóricas': Las palabras como 'Alta', 'Dióxido de Titanio' o 'ProveedorA' no son números.\n",
      "   Las convertimos en un formato numérico (0s y 1s) que el modelo pueda procesar, sin implicar un orden falso.\n",
      "Este 'preprocesador' es como una receta que aplicaremos de forma consistente a todos nuestros datos,\n",
      "tanto para el entrenamiento como para las futuras predicciones.\n",
      "\n",
      "Datos procesados. Nueva forma de X: (5000, 25)\n",
      "\n",
      "Primeras 5 filas del DataFrame de características procesadas:\n",
      "   resina_pct  pigmento_pct  solvente_pct  aditivo_pct  temperatura_mezcla_C  \\\n",
      "0    0.886468      0.913516     -1.336661    -0.897748             -1.245842   \n",
      "1    1.268060      0.758982     -1.777957    -0.221945             -0.445329   \n",
      "2   -0.348190      1.861046     -0.928874    -1.004122              1.639828   \n",
      "3    2.598166     -1.213732     -1.233845    -0.691037              0.776918   \n",
      "4    1.429961     -1.213453      0.167347    -1.630879             -0.260745   \n",
      "\n",
      "   tiempo_mezcla_min  viscosidad_cp  brillo_unidades  poder_cubriente  \\\n",
      "0          -0.875471      -0.879310         0.220878         0.843728   \n",
      "1          -0.342765      -1.134333         0.379285        -0.069299   \n",
      "2          -1.001856       0.559143         0.234972        -0.069299   \n",
      "3          -0.169328      -1.050715         0.119630        -1.895353   \n",
      "4          -0.553374       1.525166        -2.546325        -0.069299   \n",
      "\n",
      "   resistencia_abrasion_ciclos  ...  tipo_pigmento_Orgánico  \\\n",
      "0                     0.918275  ...                     0.0   \n",
      "1                     1.279212  ...                     0.0   \n",
      "2                     0.441645  ...                     1.0   \n",
      "3                    -0.762617  ...                     0.0   \n",
      "4                    -2.109529  ...                     0.0   \n",
      "\n",
      "   tipo_pigmento_Óxido de Hierro  tipo_solvente_Acetona  tipo_solvente_Agua  \\\n",
      "0                            1.0                    0.0                 0.0   \n",
      "1                            1.0                    0.0                 0.0   \n",
      "2                            0.0                    0.0                 1.0   \n",
      "3                            1.0                    0.0                 1.0   \n",
      "4                            0.0                    0.0                 1.0   \n",
      "\n",
      "   tipo_solvente_Mineral Spirits  tipo_solvente_Xileno  \\\n",
      "0                            0.0                   1.0   \n",
      "1                            0.0                   1.0   \n",
      "2                            0.0                   0.0   \n",
      "3                            0.0                   0.0   \n",
      "4                            0.0                   0.0   \n",
      "\n",
      "   proveedor_aditivo_ProveedorA  proveedor_aditivo_ProveedorB  \\\n",
      "0                           0.0                           0.0   \n",
      "1                           0.0                           0.0   \n",
      "2                           1.0                           0.0   \n",
      "3                           1.0                           0.0   \n",
      "4                           0.0                           0.0   \n",
      "\n",
      "   proveedor_aditivo_ProveedorC  proveedor_aditivo_ProveedorD  \n",
      "0                           0.0                           1.0  \n",
      "1                           0.0                           1.0  \n",
      "2                           0.0                           0.0  \n",
      "3                           0.0                           0.0  \n",
      "4                           1.0                           0.0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Preprocesador guardado exitosamente en: C:\\Users\\Víctor\\Documents\\PaintFormulatorAI\\notebooks\\..\\data\\processed\\preprocessor.joblib\n",
      "\n",
      "Explicación para Leonardo (Datos Procesados):\n",
      "Ahora, todas las características de la formulación están en un formato numérico y escalado,\n",
      "listas para ser 'consumidas' por el algoritmo de Machine Learning. El 'cerebro' del modelo\n",
      "aprenderá de estos números para identificar patrones que llevan al éxito o al fracaso.\n",
      "Hemos guardado esta 'receta' de preprocesamiento para que, cuando usted ingrese una nueva fórmula,\n",
      "la preparemos exactamente de la misma manera antes de pedirle una predicción al modelo.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 3. Preprocesamiento de Datos (Codificación y Escalado)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--------------------------------------------------\")\n",
    "print(\"3. PREPROCESAMIENTO DE DATOS\")\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "# Creamos pipelines para transformar las características:\n",
    "# 1. Para las numéricas: aplicar StandardScaler (estandarización)\n",
    "# 2. Para las categóricas: aplicar OneHotEncoder (codificación one-hot)\n",
    "\n",
    "# Paso de preprocesamiento para características numéricas: Estandarización\n",
    "# StandardScaler ajusta la media a 0 y la desviación estándar a 1.\n",
    "# Esto es vital para muchos algoritmos que son sensibles a la escala de las características.\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Paso de preprocesamiento para características categóricas: One-Hot Encoding\n",
    "# OneHotEncoder convierte cada categoría en una nueva columna binaria (0 o 1).\n",
    "# Esto evita que el modelo interprete las categorías como si tuvieran un orden.\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')) # 'ignore' para nuevas categorías en el futuro\n",
    "])\n",
    "\n",
    "# Combinar los preprocesadores usando ColumnTransformer\n",
    "# Esto permite aplicar diferentes transformaciones a diferentes columnas en paralelo.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "print(\"\\nPreprocesador configurado:\")\n",
    "print(\"- Columnas numéricas se escalarán con StandardScaler (media=0, desv_est=1).\")\n",
    "print(\"- Columnas categóricas se codificarán con OneHotEncoder (variables binarias por categoría).\")\n",
    "\n",
    "print(\"\\nExplicación para Leonardo (Preprocesamiento):\")\n",
    "print(\"Esta es una fase técnica donde preparamos los datos para el 'cerebro' del Machine Learning.\")\n",
    "print(\"1. 'Escalado de Numéricas': Componentes como 'resina_pct' o 'temperatura_mezcla_C' tienen rangos muy diferentes.\")\n",
    "print(\"   Al 'escalarlos', nos aseguramos de que ninguno de ellos 'domine' al modelo solo por tener números más grandes.\")\n",
    "print(\"   Esto ayuda a que el modelo aprenda de manera justa de todas las características.\")\n",
    "print(\"2. 'Codificación de Categóricas': Las palabras como 'Alta', 'Dióxido de Titanio' o 'ProveedorA' no son números.\")\n",
    "print(\"   Las convertimos en un formato numérico (0s y 1s) que el modelo pueda procesar, sin implicar un orden falso.\")\n",
    "print(\"Este 'preprocesador' es como una receta que aplicaremos de forma consistente a todos nuestros datos,\")\n",
    "print(\"tanto para el entrenamiento como para las futuras predicciones.\")\n",
    "\n",
    "\n",
    "# Ajustar y transformar los datos\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Obtener los nombres de las columnas después del One-Hot Encoding\n",
    "# Esto es útil para entender el DataFrame procesado\n",
    "onehot_features_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "processed_feature_names = numerical_features + onehot_features_names.tolist()\n",
    "\n",
    "# Convertir el array procesado de vuelta a un DataFrame para facilitar la visualización y análisis\n",
    "X_processed_df = pd.DataFrame(X_processed, columns=processed_feature_names)\n",
    "\n",
    "print(f\"\\nDatos procesados. Nueva forma de X: {X_processed_df.shape}\")\n",
    "print(\"\\nPrimeras 5 filas del DataFrame de características procesadas:\")\n",
    "print(X_processed_df.head())\n",
    "\n",
    "# Guardar el preprocesador ajustado para su uso futuro (en la fase de predicción)\n",
    "# Esto es vital para asegurar que las nuevas predicciones se preprocesen de la misma manera\n",
    "preprocessor_path = os.path.join(os.getcwd(), '..', 'data', 'processed', 'preprocessor.joblib')\n",
    "os.makedirs(os.path.dirname(preprocessor_path), exist_ok=True) # Asegurar que la carpeta 'processed' exista\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "print(f\"\\nPreprocesador guardado exitosamente en: {preprocessor_path}\")\n",
    "\n",
    "print(\"\\nExplicación para Leonardo (Datos Procesados):\")\n",
    "print(\"Ahora, todas las características de la formulación están en un formato numérico y escalado,\")\n",
    "print(\"listas para ser 'consumidas' por el algoritmo de Machine Learning. El 'cerebro' del modelo\")\n",
    "print(\"aprenderá de estos números para identificar patrones que llevan al éxito o al fracaso.\")\n",
    "print(\"Hemos guardado esta 'receta' de preprocesamiento para que, cuando usted ingrese una nueva fórmula,\")\n",
    "print(\"la preparemos exactamente de la misma manera antes de pedirle una predicción al modelo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da2f630-72b0-4d76-8b8e-07728c1b9e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "4. DIVISIÓN DEL DATASET EN ENTRENAMIENTO Y PRUEBA\n",
      "--------------------------------------------------\n",
      "\n",
      "Dataset dividido en entrenamiento y prueba:\n",
      "  X_train shape (características de entrenamiento): (4000, 25)\n",
      "  X_test shape (características de prueba): (1000, 25)\n",
      "  y_train shape (variable objetivo de entrenamiento): (4000,)\n",
      "  y_test shape (variable objetivo de prueba): (1000,)\n",
      "\n",
      "Balance de clases en y_train:\n",
      "exito\n",
      "1    75.0\n",
      "0    25.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Balance de clases en y_test:\n",
      "exito\n",
      "1    75.0\n",
      "0    25.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Explicación para Leonardo (División Entrenamiento/Prueba):\n",
      "Hemos dividido nuestros datos en dos partes: una para 'enseñar' al modelo (entrenamiento) y otra para 'examinarlo' (prueba).\n",
      "Imagine que está preparando a un estudiante para un examen: le da material para estudiar (datos de entrenamiento)\n",
      "y luego lo evalúa con preguntas que nunca ha visto (datos de prueba).\n",
      "Esto nos permite evaluar qué tan bien el modelo generaliza a nuevas formulaciones, y no solo qué tan bien memoriza las que ya conoce.\n",
      "La clave aquí es que la proporción de éxitos y fallas es la misma en ambos conjuntos (estratificación),\n",
      "lo cual es vital por el desbalanceo que observamos en la fase de EDA.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 4. División del Dataset en Entrenamiento y Prueba\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--------------------------------------------------\")\n",
    "print(\"4. DIVISIÓN DEL DATASET EN ENTRENAMIENTO Y PRUEBA\")\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "# test_size=0.2 (20% para prueba, 80% para entrenamiento)\n",
    "# random_state para reproducibilidad: asegura que la división sea la misma cada vez que se ejecute.\n",
    "# stratify=y para manejar el desbalanceo: asegura que la proporción de 'exito'/'falla' sea similar\n",
    "# en ambos conjuntos (entrenamiento y prueba). Esto es CRÍTICO para datasets desbalanceados.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed_df, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nDataset dividido en entrenamiento y prueba:\")\n",
    "print(f\"  X_train shape (características de entrenamiento): {X_train.shape}\")\n",
    "print(f\"  X_test shape (características de prueba): {X_test.shape}\")\n",
    "print(f\"  y_train shape (variable objetivo de entrenamiento): {y_train.shape}\")\n",
    "print(f\"  y_test shape (variable objetivo de prueba): {y_test.shape}\")\n",
    "\n",
    "# Verificar el balance de clases en los conjuntos de entrenamiento y prueba\n",
    "print(\"\\nBalance de clases en y_train:\")\n",
    "print(y_train.value_counts(normalize=True).round(2) * 100)\n",
    "print(\"\\nBalance de clases en y_test:\")\n",
    "print(y_test.value_counts(normalize=True).round(2) * 100)\n",
    "\n",
    "print(\"\\nExplicación para Leonardo (División Entrenamiento/Prueba):\")\n",
    "print(\"Hemos dividido nuestros datos en dos partes: una para 'enseñar' al modelo (entrenamiento) y otra para 'examinarlo' (prueba).\")\n",
    "print(\"Imagine que está preparando a un estudiante para un examen: le da material para estudiar (datos de entrenamiento)\")\n",
    "print(\"y luego lo evalúa con preguntas que nunca ha visto (datos de prueba).\")\n",
    "print(\"Esto nos permite evaluar qué tan bien el modelo generaliza a nuevas formulaciones, y no solo qué tan bien memoriza las que ya conoce.\")\n",
    "print(\"La clave aquí es que la proporción de éxitos y fallas es la misma en ambos conjuntos (estratificación),\")\n",
    "print(\"lo cual es vital por el desbalanceo que observamos en la fase de EDA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f575f08d-0b2e-4c22-bf62-472cf4aff567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "5. GUARDADO DE DATOS PREPROCESADOS\n",
      "--------------------------------------------------\n",
      "\n",
      "Datos de entrenamiento y prueba guardados en: C:\\Users\\Víctor\\Documents\\PaintFormulatorAI\\notebooks\\..\\data\\processed\n",
      "\n",
      "Preprocesamiento y división de datos completados. Los datos están listos para el modelado.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 5. Guardar Datos Preprocesados (Opcional, pero buena práctica)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--------------------------------------------------\")\n",
    "print(\"5. GUARDADO DE DATOS PREPROCESADOS\")\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "# Es una buena práctica guardar los conjuntos preprocesados para que los modelos\n",
    "# puedan cargarlos directamente sin necesidad de re-ejecutar todo el preprocesamiento\n",
    "# en notebooks posteriores, lo que ahorra tiempo.\n",
    "\n",
    "X_train_path = os.path.join(os.getcwd(), '..', 'data', 'processed', 'X_train.csv')\n",
    "X_test_path = os.path.join(os.getcwd(), '..', 'data', 'processed', 'X_test.csv')\n",
    "y_train_path = os.path.join(os.getcwd(), '..', 'data', 'processed', 'y_train.csv')\n",
    "y_test_path = os.path.join(os.getcwd(), '..', 'data', 'processed', 'y_test.csv')\n",
    "\n",
    "X_train.to_csv(X_train_path, index=False)\n",
    "X_test.to_csv(X_test_path, index=False)\n",
    "y_train.to_csv(y_train_path, index=False)\n",
    "y_test.to_csv(y_test_path, index=False)\n",
    "\n",
    "print(f\"\\nDatos de entrenamiento y prueba guardados en: {os.path.join(os.getcwd(), '..', 'data', 'processed')}\")\n",
    "\n",
    "print(\"\\nPreprocesamiento y división de datos completados. Los datos están listos para el modelado.\")\n",
    "print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb19855-84f6-42f6-8f2d-3007e2a8dc66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0381a77-8081-47c2-a516-cd3ef1eb1da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398b88e-4275-4b6a-ae8c-207d9d01f7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2b118-6baf-475c-9ee2-646940de1708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573de4c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fde031",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
